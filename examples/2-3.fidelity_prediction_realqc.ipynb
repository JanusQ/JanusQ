{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fidelity Prediction Of JanusQ-CT on Real Quantum Device\n",
    "\n",
    "**Author:** Congliang Lang \\& Siwei Tan  \n",
    "\n",
    "**Date:** 7/4/2024\n",
    "\n",
    "Based on \"[QuCT: A Framework for Analyzing Quantum Circuit by Extracting Contextual and Topological Features (MICRO 2023][1]\"\n",
    "\n",
    "[1]: https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/abs/10.1145/3613424.3614274%3Fcasa_token%3DffjIB1hQ4ZwAAAAA:8MajDLrDOC74WoeMf7r7AoQ-koxCa4E1TNqQg3GSDz03xUX6XdE3toNTM-YdM_e4rKEusMceJ6BGJg&hl=zh-CN&sa=T&oi=gsb&ct=res&cd=0&d=11146218754516883150&ei=42YSZpPlFL6s6rQPtt6x6Ac&scisig=AFWwaeYaiu2hyx8HUJ_7Buf9Mwom\n",
    "\n",
    "\n",
    "In this notebook, we use the fidelity dataset of a custom superconducting quantum devices to evaluate the fidelity prediction model of Janus-CT. This device is custom with 18 Xmon qubits arranged in a 6×3 grid qubit topology and use RX, RY, RZ, and CZ gates as basis gates, with gate times of 30 ns and 60 ns for single-qubit and two-qubit gates, respectively. The single-qubit gate fidelity, two-qubit fidelity and measurement are 99.97\\%, 99.16\\% and 94.91\\%, repsecitvely, are benchmarked by isolated RB. For simultaneous RB, the single-qubit and two-qubit fidelities of both devices are above 99\\% and 98\\%, respectively.\n",
    "\n",
    "<div style=\"text-align:center;\">\n",
    "    <img src=\"pictures/2-3.processor_topology.png\"  width=\"20%\" height=\"20%\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"..\")\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "from janusq.analysis.fidelity_prediction import FidelityModel\n",
    "from janusq.baselines.fidelity_prediction.rb_prediction import RBModel\n",
    "\n",
    "from janusq.analysis.vectorization import RandomwalkModel\n",
    "\n",
    "from janusq.data_objects.backend import GridBackend\n",
    "\n",
    "from janusq.tools.ray_func import map\n",
    "\n",
    "from janusq.data_objects.circuit import SeperatableCircuit\n",
    "\n",
    "from janusq.tools.ray_func import map\n",
    "import numpy as np\n",
    "import ray\n",
    "\n",
    "runtime_envs = {\"working_dir\": os.getcwd}\n",
    "ray.init(log_to_driver=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load fidelity dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500\n"
     ]
    }
   ],
   "source": [
    "import io\n",
    "import pickle\n",
    "\n",
    "\n",
    "class RenameUnpickler(pickle.Unpickler):\n",
    "    def find_class(self, module, name):\n",
    "\n",
    "        renamed_module = module\n",
    "        if module.startswith(\"data_objects\"):# or module.startwith(\"analysis\") or module.startwith(\"data_objects\")\n",
    "            renamed_module = \"janusq.\" + module\n",
    "\n",
    "        return super(RenameUnpickler, self).find_class(renamed_module, name)\n",
    "\n",
    "\n",
    "def renamed_load(file_obj):\n",
    "    return RenameUnpickler(file_obj).load()\n",
    "\n",
    "\n",
    "\n",
    "import pickle\n",
    "with open(\"examples/dataset/fidelity_dataset_18q.pkl\", \"rb\") as f:\n",
    "    circuits: list[SeperatableCircuit] = renamed_load(f)   # TODO: 整理成circuits一个数组，fidelity一个数组的形式\n",
    "print(len(circuits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# limit the number of circuits to speedup the model construction\n",
    "circuits = circuits[:200]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A large amount of zero-valued fidelities means less valid information, which negatively affects the training convergence and the model accuracy. For large-scale quantum device, e.g., 18-qubit device, we use seperable circuits to pervent the final fidelity from vanishing to zero due to a large number of gates. To address this, the separable circuits used in the fidelity dataset restrict the entangled qubits into sub-circuits within a small number of qubits.\n",
    "\n",
    "<div style=\"text-align:center;\">\n",
    "    <img src=\"pictures/2-3.lagre_fidelity.jpg\"  width=\"40%\" height=\"40%\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800 800\n"
     ]
    }
   ],
   "source": [
    "sub_circuits, sub_fidelities = [], []\n",
    "for circuit in circuits:\n",
    "    for sub_cir in circuit.seperatable_circuits:\n",
    "        sub_circuits.append(sub_cir)\n",
    "        sub_fidelities.append(sub_cir.ground_truth_fidelity)\n",
    "\n",
    "print(len(sub_circuits), len(sub_fidelities))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate train datset and test dataset\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_cirucits, test_circuits, train_fidelities, test_fidelities = train_test_split(sub_circuits,  sub_fidelities, test_size=.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Vectorization Model\n",
    "\n",
    "To train the fidelity prediction model, we first build the vectorization model for the quanutm device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:start random walk for 200 circuits\n",
      "100%|██████████| 20/20 [00:02<00:00,  7.58it/s]\n",
      "INFO:root:count path\n",
      "INFO:root:device size after random walk = 34\n",
      "INFO:root:0's path table size = 621\n",
      "INFO:root:1's path table size = 618\n",
      "INFO:root:2's path table size = 615\n",
      "INFO:root:3's path table size = 621\n",
      "INFO:root:4's path table size = 618\n",
      "INFO:root:5's path table size = 618\n",
      "INFO:root:6's path table size = 618\n",
      "INFO:root:7's path table size = 618\n",
      "INFO:root:8's path table size = 621\n",
      "INFO:root:9's path table size = 621\n",
      "INFO:root:10's path table size = 618\n",
      "INFO:root:11's path table size = 615\n",
      "INFO:root:12's path table size = 618\n",
      "INFO:root:13's path table size = 615\n",
      "INFO:root:14's path table size = 621\n",
      "INFO:root:15's path table size = 618\n",
      "INFO:root:16's path table size = 621\n",
      "INFO:root:17's path table size = 621\n",
      "INFO:root:(6, 12)'s path table size = 202\n",
      "INFO:root:(12, 13)'s path table size = 201\n",
      "INFO:root:(2, 8)'s path table size = 202\n",
      "INFO:root:(11, 17)'s path table size = 202\n",
      "INFO:root:(13, 14)'s path table size = 202\n",
      "INFO:root:(7, 13)'s path table size = 201\n",
      "INFO:root:(4, 5)'s path table size = 202\n",
      "INFO:root:(0, 1)'s path table size = 203\n",
      "INFO:root:(1, 2)'s path table size = 201\n",
      "INFO:root:(10, 11)'s path table size = 201\n",
      "INFO:root:(6, 7)'s path table size = 202\n",
      "INFO:root:(15, 16)'s path table size = 203\n",
      "INFO:root:(4, 10)'s path table size = 202\n",
      "INFO:root:(5, 11)'s path table size = 201\n",
      "INFO:root:(2, 3)'s path table size = 202\n",
      "INFO:root:(9, 15)'s path table size = 203\n"
     ]
    }
   ],
   "source": [
    "n_qubits = 18\n",
    "n_steps = 1\n",
    "n_walks = 20\n",
    "backend = GridBackend(3, 6)\n",
    "\n",
    "vec_model = RandomwalkModel(n_steps = n_steps, n_walks = n_walks, backend = backend)\n",
    "vec_model.train(circuits, multi_process = True, remove_redundancy = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Fidelity Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:len(train dataset) = 512, len(validation dataset) = 128\n",
      "INFO:jax._src.xla_bridge:Unable to initialize backend 'cuda': \n",
      "INFO:jax._src.xla_bridge:Unable to initialize backend 'rocm': module 'jaxlib.xla_extension' has no attribute 'GpuAllocatorConfig'\n",
      "INFO:jax._src.xla_bridge:Unable to initialize backend 'tpu': INTERNAL: Failed to open libtpu.so: libtpu.so: cannot open shared object file: No such file or directory\n",
      "512it [00:00, 642766.73it/s]\n",
      "/home/JanusQ-main/janusq/analysis/fidelity_prediction.py:69: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in array is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  return jnp.array(vec_model.vectorize(circuit), jnp.float64)\n",
      "128it [00:00, 481930.80it/s]\n",
      "INFO:root:epoch: 0, \t epoch loss = 425.64532470703125, \t validation loss = 1.6341722011566162\n",
      "INFO:root:epoch: 100, \t epoch loss = 142.8127899169922, \t validation loss = 1.0577054023742676\n",
      "INFO:root:epoch: 200, \t epoch loss = 132.7703399658203, \t validation loss = 1.041447639465332\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m在当前单元格或上一个单元格中执行代码时 Kernel 崩溃。\n",
      "\u001b[1;31m请查看单元格中的代码，以确定故障的可能原因。\n",
      "\u001b[1;31m单击<a href='https://aka.ms/vscodeJupyterKernelCrash'>此处</a>了解详细信息。\n",
      "\u001b[1;31m有关更多详细信息，请查看 Jupyter <a href='command:jupyter.viewOutput'>log</a>。"
     ]
    }
   ],
   "source": [
    "fidelity_model = FidelityModel(vec_model)\n",
    "fidelity_model.train((train_cirucits, train_fidelities), multi_process = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Janus-CT can also evaluate the weight of each path to identify high source of error. For example, when two gates leads to high error when they are in the same layer. It may result from crosstalk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fidelity_model.plot_path_error()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare to Random Benchmarking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the 1-q fidelities and 2-q fidelities of rb \n",
    "fidelity_1q_rb = {0: 0.9994094148043156, 1: 0.9993508083886652, 2: 0.9993513578387458, 3: 0.9996978330672296, 4: 0.9997258463524775, \n",
    "                           5: 0.9993898065578337, 6: 0.9998335484697743, 7: 0.9997460044815009,  8: 0.9997219426985601, 9: 0.9992924485427597, \n",
    "                           10: 0.9994018918682177, 11: 0.9998410411794697, 12: 0.9994231683912435, 13: 0.9995938422219371, 14: 0.9947661045069707, \n",
    "                           15: 0.9997576786354693, 16: 0.9998387638441334,  17: 0.9996691783504945} \n",
    "fidelity_2q_rb = {(5,11): 0.993651602350742, (11,17): 0.9943374306798481,  (4,5): 0.9810612795342519,  (10,11): 0.9915544427978213,  \n",
    "                           (16,17): 0.9908639448675425,  (4,10): 0.9914941121128581,  (10,16): 0.9868303060599511,  (3,4): 0.9899226069903224,  \n",
    "                           (9,10): 0.9945250360193374,  (15,16): 0.9933864398113101,  (3,9): 0.991508018299962,  (9,15): 0.993773364368622,  \n",
    "                           (2,3): 0.9802169505904027,  (8,9): 0.9912794178832776,  (14,15): 0.9867247971867894,  (2,8): 0.9765590682588615,  \n",
    "                           (8,14): 0.9863913339619792,  (1,2): 0.9713229087974011,  (7,8): 0.9908463216114999,  (13,14): 0.9564265490465305,  \n",
    "                           (1,7): 0.9856880460026779,  (7,13): 0.9935440562158602,  (0,1): 0.9833453296232256,  (6,7): 0.9939901490743566,  \n",
    "                           (12,13): 0.9821366244436676,  (0,6): 0.9861987068804432,  (6,12): 0.9863008252688662} \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rb_fidelities = np.array(map(lambda circuit: RBModel.get_rb_fidelity(circuit, fidelity_1q_rb, fidelity_2q_rb), test_circuits))\n",
    "janusct_fidelities = np.array(map(lambda circuit: fidelity_model.predict_circuit_fidelity(circuit), test_circuits))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from janusq.tools.plot import plot_scaater\n",
    "\n",
    "durations = np.array([cir.duration for cir in test_circuits])\n",
    "\n",
    "fig_quct, axes_quct = plot_scaater(test_fidelities, janusct_fidelities, durations, title = f\"janusct inaccuracy = {np.abs(test_fidelities - janusct_fidelities).mean()}\")\n",
    "fig_rb, axes_rb = plot_scaater(test_fidelities, rb_fidelities, durations, title = f\"rb inaccuracy = {np.abs(test_fidelities - rb_fidelities).mean()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "janusq",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
