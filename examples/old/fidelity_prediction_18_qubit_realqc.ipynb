{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "import packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "os.chdir('..')\n",
        "\n",
        "from analysis.fidelity_prediction import FidelityModel\n",
        "from baselines.fidelity_prediction.rb_prediction import RBModel\n",
        "from simulator.gate_error_model import GateErrorModel\n",
        "\n",
        "from analysis.vectorization import RandomwalkModel\n",
        "\n",
        "from data_objects.random_circuit import random_circuits, random_circuit\n",
        "from data_objects.backend import Backend, LinearBackend, GridBackend, FullyConnectedBackend\n",
        "\n",
        "from simulator.noisy_simulator import NoisySimulator\n",
        "import random\n",
        "from dataset import load_dataset\n",
        "from tools.ray_func import map\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "model settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "n_qubits = 18\n",
        "n_steps = 2\n",
        "n_walks = 20\n",
        "backend = GridBackend(3, 6)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "load dataset with ground truth fidelity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "from data_objects.circuit import SeperatableCircuit\n",
        "\n",
        "dataset_id = '20230321'\n",
        "circuits: list[SeperatableCircuit] = load_dataset(dataset_id)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "train upstream model, turn a circuit to vectors using random walk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "start random walk for 2500 circuits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/langcongliang/enter/envs/janusq/lib/python3.10/subprocess.py:1796: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = _posixsubprocess.fork_exec(\n",
            "2024-03-29 18:00:50,806\tINFO worker.py:1724 -- Started a local Ray instance.\n",
            "100%|██████████| 10/10 [01:50<00:00, 11.06s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "count path\n",
            "device size after random walk = 41\n",
            "0's path table size = 16761\n",
            "1's path table size = 16765\n",
            "2's path table size = 17614\n",
            "3's path table size = 17207\n",
            "4's path table size = 19494\n",
            "5's path table size = 19421\n",
            "6's path table size = 16949\n",
            "7's path table size = 17406\n",
            "8's path table size = 16983\n",
            "9's path table size = 21902\n",
            "10's path table size = 19675\n",
            "11's path table size = 19693\n",
            "12's path table size = 17991\n",
            "13's path table size = 20824\n",
            "14's path table size = 20799\n",
            "15's path table size = 23123\n",
            "16's path table size = 21958\n",
            "17's path table size = 19434\n",
            "(6, 12)'s path table size = 5264\n",
            "(3, 4)'s path table size = 3290\n",
            "(16, 17)'s path table size = 3080\n",
            "(12, 13)'s path table size = 4097\n",
            "(2, 8)'s path table size = 3899\n",
            "(11, 17)'s path table size = 6336\n",
            "(13, 14)'s path table size = 6874\n",
            "(7, 13)'s path table size = 4035\n",
            "(4, 5)'s path table size = 4008\n",
            "(3, 9)'s path table size = 3321\n",
            "(14, 15)'s path table size = 4065\n",
            "(0, 1)'s path table size = 3260\n",
            "(1, 2)'s path table size = 6307\n",
            "(10, 11)'s path table size = 6413\n",
            "(6, 7)'s path table size = 5367\n",
            "(15, 16)'s path table size = 5307\n",
            "(4, 10)'s path table size = 3972\n",
            "(5, 11)'s path table size = 6353\n",
            "(0, 6)'s path table size = 2528\n",
            "(2, 3)'s path table size = 5936\n",
            "(9, 15)'s path table size = 5310\n",
            "(10, 16)'s path table size = 2881\n",
            "(7, 8)'s path table size = 2377\n"
          ]
        }
      ],
      "source": [
        "vec_model = RandomwalkModel(n_steps = n_steps, n_walks = n_walks, backend = backend)\n",
        "gate_vecs_per_circuit = vec_model.train(circuits, True, remove_redundancy = False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "select interaction patterns randomly, simulate interaction between gates"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "flaten_circuits, flaten_fidelities = [], []\n",
        "for circuit in circuits:\n",
        "    for sub_cir in circuit.seperatable_circuits:\n",
        "        flaten_circuits.append(sub_cir)\n",
        "        flaten_fidelities.append(sub_cir.ground_truth_fidelity)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "train fidelity prediction model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "An NVIDIA GPU may be present on this machine, but a CUDA-enabled jaxlib is not installed. Falling back to cpu.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "len(train dataset) = 8000, len(validation dataset) = 2000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "8000it [00:00, 1084009.56it/s]\n",
            "100%|██████████| 74/74 [00:02<00:00, 33.69it/s]\n",
            "100%|██████████| 77/77 [00:00<00:00, 140.27it/s]\n",
            "100%|██████████| 39/39 [00:01<00:00, 26.81it/s]\n",
            "100%|██████████| 78/78 [00:02<00:00, 36.44it/s]\n",
            "100%|██████████| 39/39 [00:01<00:00, 25.80it/s]\n",
            "100%|██████████| 66/66 [00:02<00:00, 31.37it/s]\n",
            "100%|██████████| 77/77 [00:01<00:00, 62.84it/s]\n",
            "100%|██████████| 76/76 [00:00<00:00, 84.97it/s] \n",
            "100%|██████████| 30/30 [00:01<00:00, 21.73it/s]\n",
            "100%|██████████| 77/77 [00:01<00:00, 45.30it/s]\n",
            "100%|██████████| 77/77 [00:01<00:00, 54.65it/s]\n",
            "100%|██████████| 38/38 [00:01<00:00, 22.86it/s]\n",
            "100%|██████████| 39/39 [00:01<00:00, 26.28it/s]\n",
            "100%|██████████| 20/20 [00:00<00:00, 139.36it/s]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_map pid=3435886)\u001b[0m /home/langcongliang/janusq/analysis/fidelity_prediction.py:84: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in array is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
            "\u001b[36m(_map pid=3435886)\u001b[0m   return jnp.array(vec_model.vectorize(circuit), jnp.float64)\n",
            "\u001b[36m(_map pid=3435886)\u001b[0m An NVIDIA GPU may be present on this machine, but a CUDA-enabled jaxlib is not installed. Falling back to cpu.\n",
            "\u001b[36m(_map pid=3435737)\u001b[0m /home/langcongliang/janusq/analysis/fidelity_prediction.py:84: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in array is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\u001b[32m [repeated 4x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/ray-logging.html#log-deduplication for more options.)\u001b[0m\n",
            "\u001b[36m(_map pid=3435737)\u001b[0m   return jnp.array(vec_model.vectorize(circuit), jnp.float64)\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(_map pid=3435483)\u001b[0m An NVIDIA GPU may be present on this machine, but a CUDA-enabled jaxlib is not installed. Falling back to cpu.\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[36m(_map pid=3435886)\u001b[0m /home/langcongliang/janusq/analysis/fidelity_prediction.py:84: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in array is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_map pid=3435886)\u001b[0m   return jnp.array(vec_model.vectorize(circuit), jnp.float64)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_map pid=3435345)\u001b[0m /home/langcongliang/janusq/analysis/fidelity_prediction.py:84: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in array is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[36m(_map pid=3435345)\u001b[0m   return jnp.array(vec_model.vectorize(circuit), jnp.float64)\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[36m(_map pid=3435483)\u001b[0m /home/langcongliang/janusq/analysis/fidelity_prediction.py:84: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in array is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
            "\u001b[36m(_map pid=3435483)\u001b[0m   return jnp.array(vec_model.vectorize(circuit), jnp.float64)\n",
            "\u001b[36m(_map pid=3435737)\u001b[0m /home/langcongliang/janusq/analysis/fidelity_prediction.py:84: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in array is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
            "\u001b[36m(_map pid=3435737)\u001b[0m   return jnp.array(vec_model.vectorize(circuit), jnp.float64)\n",
            "\u001b[36m(_map pid=3435886)\u001b[0m /home/langcongliang/janusq/analysis/fidelity_prediction.py:84: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in array is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_map pid=3435886)\u001b[0m   return jnp.array(vec_model.vectorize(circuit), jnp.float64)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_map pid=3435886)\u001b[0m /home/langcongliang/janusq/analysis/fidelity_prediction.py:84: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in array is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
            "\u001b[36m(_map pid=3435886)\u001b[0m   return jnp.array(vec_model.vectorize(circuit), jnp.float64)\n",
            "\u001b[36m(_map pid=3435483)\u001b[0m /home/langcongliang/janusq/analysis/fidelity_prediction.py:84: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in array is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
            "\u001b[36m(_map pid=3435483)\u001b[0m   return jnp.array(vec_model.vectorize(circuit), jnp.float64)\n",
            "\u001b[36m(_map pid=3435522)\u001b[0m An NVIDIA GPU may be present on this machine, but a CUDA-enabled jaxlib is not installed. Falling back to cpu.\n",
            "\u001b[36m(_map pid=3435886)\u001b[0m /home/langcongliang/janusq/analysis/fidelity_prediction.py:84: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in array is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(_map pid=3435886)\u001b[0m   return jnp.array(vec_model.vectorize(circuit), jnp.float64)\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(_map pid=3435345)\u001b[0m /home/langcongliang/janusq/analysis/fidelity_prediction.py:84: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in array is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(_map pid=3435345)\u001b[0m   return jnp.array(vec_model.vectorize(circuit), jnp.float64)\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(_map pid=3435886)\u001b[0m /home/langcongliang/janusq/analysis/fidelity_prediction.py:84: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in array is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_map pid=3435886)\u001b[0m   return jnp.array(vec_model.vectorize(circuit), jnp.float64)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_map pid=3435886)\u001b[0m /home/langcongliang/janusq/analysis/fidelity_prediction.py:84: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in array is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_map pid=3435886)\u001b[0m   return jnp.array(vec_model.vectorize(circuit), jnp.float64)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_map pid=3435483)\u001b[0m /home/langcongliang/janusq/analysis/fidelity_prediction.py:84: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in array is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(_map pid=3435483)\u001b[0m   return jnp.array(vec_model.vectorize(circuit), jnp.float64)\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(_map pid=3435736)\u001b[0m An NVIDIA GPU may be present on this machine, but a CUDA-enabled jaxlib is not installed. Falling back to cpu.\n",
            "\u001b[36m(_map pid=3435345)\u001b[0m /home/langcongliang/janusq/analysis/fidelity_prediction.py:84: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in array is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_map pid=3435345)\u001b[0m   return jnp.array(vec_model.vectorize(circuit), jnp.float64)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_map pid=3435483)\u001b[0m /home/langcongliang/janusq/analysis/fidelity_prediction.py:84: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in array is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[36m(_map pid=3435483)\u001b[0m   return jnp.array(vec_model.vectorize(circuit), jnp.float64)\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[36m(_map pid=3435345)\u001b[0m /home/langcongliang/janusq/analysis/fidelity_prediction.py:84: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in array is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[36m(_map pid=3435345)\u001b[0m   return jnp.array(vec_model.vectorize(circuit), jnp.float64)\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[36m(_map pid=3435345)\u001b[0m /home/langcongliang/janusq/analysis/fidelity_prediction.py:84: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in array is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(_map pid=3435345)\u001b[0m   return jnp.array(vec_model.vectorize(circuit), jnp.float64)\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(_map pid=3435345)\u001b[0m /home/langcongliang/janusq/analysis/fidelity_prediction.py:84: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in array is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(_map pid=3435345)\u001b[0m   return jnp.array(vec_model.vectorize(circuit), jnp.float64)\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(_map pid=3435737)\u001b[0m /home/langcongliang/janusq/analysis/fidelity_prediction.py:84: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in array is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[36m(_map pid=3435737)\u001b[0m   return jnp.array(vec_model.vectorize(circuit), jnp.float64)\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[36m(_map pid=3435886)\u001b[0m /home/langcongliang/janusq/analysis/fidelity_prediction.py:84: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in array is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_map pid=3435886)\u001b[0m   return jnp.array(vec_model.vectorize(circuit), jnp.float64)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_map pid=3435736)\u001b[0m /home/langcongliang/janusq/analysis/fidelity_prediction.py:84: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in array is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(_map pid=3435736)\u001b[0m   return jnp.array(vec_model.vectorize(circuit), jnp.float64)\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(_map pid=3435483)\u001b[0m /home/langcongliang/janusq/analysis/fidelity_prediction.py:84: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in array is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(_map pid=3435483)\u001b[0m   return jnp.array(vec_model.vectorize(circuit), jnp.float64)\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(_map pid=3435483)\u001b[0m /home/langcongliang/janusq/analysis/fidelity_prediction.py:84: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in array is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(_map pid=3435483)\u001b[0m   return jnp.array(vec_model.vectorize(circuit), jnp.float64)\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(_map pid=3435483)\u001b[0m /home/langcongliang/janusq/analysis/fidelity_prediction.py:84: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in array is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[36m(_map pid=3435483)\u001b[0m   return jnp.array(vec_model.vectorize(circuit), jnp.float64)\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[36m(_map pid=3435345)\u001b[0m /home/langcongliang/janusq/analysis/fidelity_prediction.py:84: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in array is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(_map pid=3435345)\u001b[0m   return jnp.array(vec_model.vectorize(circuit), jnp.float64)\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(_map pid=3435886)\u001b[0m /home/langcongliang/janusq/analysis/fidelity_prediction.py:84: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in array is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
            "\u001b[36m(_map pid=3435886)\u001b[0m   return jnp.array(vec_model.vectorize(circuit), jnp.float64)\n",
            "\u001b[36m(_map pid=3435345)\u001b[0m /home/langcongliang/janusq/analysis/fidelity_prediction.py:84: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in array is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
            "\u001b[36m(_map pid=3435345)\u001b[0m   return jnp.array(vec_model.vectorize(circuit), jnp.float64)\n",
            "\u001b[36m(_map pid=3435345)\u001b[0m /home/langcongliang/janusq/analysis/fidelity_prediction.py:84: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in array is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
            "\u001b[36m(_map pid=3435345)\u001b[0m   return jnp.array(vec_model.vectorize(circuit), jnp.float64)\n",
            "\u001b[36m(_map pid=3435886)\u001b[0m /home/langcongliang/janusq/analysis/fidelity_prediction.py:84: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in array is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
            "\u001b[36m(_map pid=3435886)\u001b[0m   return jnp.array(vec_model.vectorize(circuit), jnp.float64)\n",
            "\u001b[36m(_map pid=3435345)\u001b[0m /home/langcongliang/janusq/analysis/fidelity_prediction.py:84: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in array is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(_map pid=3435345)\u001b[0m   return jnp.array(vec_model.vectorize(circuit), jnp.float64)\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "n_gates_list: [20, 30, 40, 50, 60, 70, 80, 90, 100, 110, 120, 130, 140, 150]\n",
            "n_gates_count_list: [199, 770, 760, 764, 765, 769, 772, 734, 652, 381, 386, 381, 374, 293]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2000it [00:00, 238672.09it/s]\n",
            "100%|██████████| 20/20 [00:00<00:00, 83.67it/s]\n",
            "100%|██████████| 20/20 [00:00<00:00, 70.67it/s] \n",
            "100%|██████████| 10/10 [00:00<00:00, 13.33it/s]\n",
            "100%|██████████| 19/19 [00:00<00:00, 83.91it/s]\n",
            "100%|██████████| 7/7 [00:00<00:00, 10.12it/s]\n",
            "100%|██████████| 19/19 [00:00<00:00, 41.93it/s]\n",
            "100%|██████████| 20/20 [00:00<00:00, 85.51it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 23.88it/s]\n",
            "100%|██████████| 21/21 [00:00<00:00, 43.85it/s]\n",
            "100%|██████████| 20/20 [00:00<00:00, 77.35it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 13.64it/s]\n",
            "100%|██████████| 13/13 [00:00<00:00, 18.95it/s]\n",
            "100%|██████████| 11/11 [00:00<00:00, 17.67it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 45.36it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "n_gates_list: [20, 30, 40, 50, 60, 70, 80, 90, 100, 110, 120, 130, 140, 150]\n",
            "n_gates_count_list: [41, 190, 200, 196, 195, 191, 188, 206, 128, 99, 94, 99, 106, 67]\n",
            "epoch: 0, \t epoch loss = 48583.08984375, \t validation loss = 3.815769910812378\n"
          ]
        }
      ],
      "source": [
        "fidelity_model = FidelityModel(vec_model)\n",
        "fidelity_model.train((flaten_circuits, flaten_fidelities))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "predict on test dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "compare with RB predict model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "from matplotlib import cm\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.colors import LinearSegmentedColormap\n",
        "import numpy as np\n",
        "import random\n",
        "def plot_scaater(reals, predicts, durations ,name):\n",
        "    par = np.polyfit(reals, predicts, 1, full=True)\n",
        "    slope=par[0][0]\n",
        "    intercept=par[0][1]\n",
        "    x1 = [0.4, 1.0]\n",
        "    y1 = [slope*xx + intercept  for xx in x1]\n",
        "    #定义颜色\n",
        "    colors = [\"#FF3636\", '#277C8E' ,\"#1F77B4\"]\n",
        "    '''xia <- shang'''\n",
        "    # colors.reverse()\n",
        "    # colors = np.array(colors) / 256\n",
        "    # 定义颜色的位置\n",
        "    pos = [0, .5, 1]\n",
        "    # 创建colormap对象\n",
        "    cmap = LinearSegmentedColormap.from_list('my_colormap', list(zip(pos, colors)))\n",
        "\n",
        "    normalied_durations = (durations - durations.min())/(durations.max() - durations.min())\n",
        "\n",
        "    # cmap_name = 'Blues'\n",
        "    # cmap_name = 'viridis'\n",
        "    # cmap_name = 'plasma'\n",
        "    # cmap_name = 'winter'\n",
        "\n",
        "    random_index = list(range(len(reals)))\n",
        "    random.shuffle(random_index)\n",
        "    random_index = random_index[:1500]\n",
        "    reals = np.array(reals)\n",
        "    predicts = np.array(predicts)\n",
        "    fig, axes = plt.subplots(figsize=(10, 10))  # 创建一个图形对象和一个子图对象\n",
        "    axes.axis([0, 1, 0, 1])\n",
        "    axes.scatter(reals[random_index], predicts[random_index], c= normalied_durations[random_index], cmap=cmap,alpha = 0.6, s=80 )\n",
        "    axes.plot(x1,y1)\n",
        "    axes.set_xlim(.2, 1)\n",
        "    axes.set_ylim(.2, 1)\n",
        "    axes.set_xlabel('real ')\n",
        "    axes.set_ylabel('predict')\n",
        "    axes.plot([[0,0],[1,1]])\n",
        "    # fig.colorbar(cm.ScalarMappable( cmap=cmap))\n",
        "    fig.savefig(name)\n",
        "    print(slope, intercept)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "janusq",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
